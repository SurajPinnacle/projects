{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_icons_feature_based(image_path, template_paths, threshold, output_folder, icon_name):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load the image from '{image_path}'.\")\n",
    "        return\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img_detected = img.copy()\n",
    "    detected_points = []\n",
    "\n",
    "    # Initialize ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Iterate over each template\n",
    "    for template_path in template_paths:\n",
    "        template = cv2.imread(template_path, 0)\n",
    "        if template is None:\n",
    "            print(f\"Error: Unable to load the template '{template_path}'.\")\n",
    "            continue\n",
    "        \n",
    "        # Find keypoints and descriptors in the floor plan and the template\n",
    "        kp1, des1 = orb.detectAndCompute(img_gray, None)\n",
    "        kp2, des2 = orb.detectAndCompute(template, None)\n",
    "\n",
    "        # Ensure descriptors are the correct type (CV_8U)\n",
    "        des1 = np.asarray(des1, dtype=np.uint8) if des1 is not None else None\n",
    "        des2 = np.asarray(des2, dtype=np.uint8) if des2 is not None else None\n",
    "\n",
    "        # Check if descriptors are not None and of the correct type\n",
    "        if des1 is None or des2 is None:\n",
    "            print(\"Error: Descriptors are None for one of the images.\")\n",
    "            continue\n",
    "\n",
    "        # Use BFMatcher to match descriptors\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = bf.match(des1, des2)\n",
    "\n",
    "        # Sort matches based on distance\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "        # Define a threshold for good matches (you can tune this value)\n",
    "        good_matches = [m for m in matches if m.distance < threshold]\n",
    "        \n",
    "        # If enough good matches are found, proceed\n",
    "        if len(good_matches) > 5:\n",
    "            # Extract the matching keypoints\n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "            # Find homography (transformation matrix)\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "            # Get the size of the template\n",
    "            h, w = template.shape\n",
    "            pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "            dst = cv2.perspectiveTransform(pts, M)\n",
    "\n",
    "            # Draw the bounding box around the matched region\n",
    "            img_detected = cv2.polylines(img_detected, [np.int32(dst)], True, (0, 255, 0), 3)\n",
    "            detected_points.append(dst)\n",
    "    \n",
    "    # Show and save the final result\n",
    "    cv2.imshow(\"Detected Icons\", img_detected)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    filename = f\"{icon_name}_detected.jpg\"\n",
    "    filepath = os.path.join(output_folder, filename)\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    cv2.imwrite(filepath, img_detected)\n",
    "    print(f\"Result saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_folder: C:/Users/pis05408.PINNACLE/Desktop/Suraj/ObjectDetectionFlorPlan/Test\n"
     ]
    }
   ],
   "source": [
    "output_folder = 'C:/Users/pis05408.PINNACLE/Desktop/Suraj/ObjectDetectionFlorPlan/Test'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "print(f'output_folder: {output_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your target image and templates\n",
    "image_path = 'data/sample.jpg'\n",
    "# template_paths = ['data/test.jpg', 'data/test1.jpg', 'data/test1.jpg', 'data/test2.jpg', 'data/test3.jpg', 'data/test4.jpg', 'data/test5.jpg', 'data/test6.jpg']\n",
    "template_paths = ['data/test.jpg']\n",
    "\n",
    "# Read the images\n",
    "image = cv2.imread(image_path)\n",
    "templates = [cv2.imread(template_path) for template_path in template_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Descriptors are None for one of the images.\n",
      "Result saved to C:/Users/pis05408.PINNACLE/Desktop/Suraj/ObjectDetectionFlorPlan/Test\\testorb_detected.jpg\n"
     ]
    }
   ],
   "source": [
    "# Define scales and angles\n",
    "# scales = np.linspace(0.5, 1.2, num=10)  # Adjust scale range and steps as needed\n",
    "scales = np.arange(0.5, 1.2, 0.1)\n",
    "\n",
    "# Define threshold\n",
    "threshold = 0.7  # Adjust based on experimentation\n",
    "\n",
    "icon_name = 'testorb'\n",
    "\n",
    "# Call the detection function\n",
    "detect_icons_feature_based(image_path, template_paths, threshold, output_folder, icon_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rotate_image(image, angle):\n",
    "#     (h, w) = image.shape[:2]\n",
    "#     center = (w / 2, h / 2)\n",
    "#     M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "#     cos = np.abs(M[0, 0])\n",
    "#     sin = np.abs(M[0, 1])\n",
    "#     new_w = int((h * sin) + (w * cos))\n",
    "#     new_h = int((h * cos) + (w * sin))\n",
    "#     M[0, 2] += (new_w / 2) - center[0]\n",
    "#     M[1, 2] += (new_h / 2) - center[1]\n",
    "#     rotated = cv2.warpAffine(image, M, (new_w, new_h))\n",
    "#     return rotated\n",
    "\n",
    "# def multi_scale_and_angle_template_matching(image, templates, threshold=0.7):\n",
    "#     bounding_boxes = []\n",
    "\n",
    "#     for template in templates:\n",
    "#         h, w = template.shape[:2]\n",
    "        \n",
    "#         # Loop over scales\n",
    "#         for scale in np.linspace(0.5, 1.5, num=10):  # Adjust scale range as needed\n",
    "#             resized_template = cv2.resize(template, (int(w * scale), int(h * scale)))\n",
    "#             res_h, res_w = resized_template.shape[:2]\n",
    "\n",
    "#             # Skip if resized template is larger than the image\n",
    "#             if res_h > image.shape[0] or res_w > image.shape[1]:\n",
    "#                 continue\n",
    "\n",
    "#             # Loop over angles\n",
    "#             for angle in [90, 180, 270]:  # Adjust angle step as needed\n",
    "#                 M = cv2.getRotationMatrix2D((res_w / 2, res_h / 2), angle, 1.0)\n",
    "#                 rotated_template = cv2.warpAffine(resized_template, M, (res_w, res_h))\n",
    "\n",
    "#                 # Template matching\n",
    "#                 result = cv2.matchTemplate(image, rotated_template, cv2.TM_CCOEFF_NORMED)\n",
    "#                 loc = np.where(result >= threshold)\n",
    "\n",
    "#                 # Record all locations where matches are found\n",
    "#                 for pt in zip(*loc[::-1]):  # Switch x and y coordinates\n",
    "#                     bounding_boxes.append((pt[0], pt[1], res_w, res_h))  # (x, y, width, height)\n",
    "\n",
    "#     return bounding_boxes\n",
    "\n",
    "# def non_max_suppression(boxes, overlapThresh=0.7):\n",
    "#     if len(boxes) == 0:\n",
    "#         return []\n",
    "\n",
    "#     boxes = np.array(boxes)\n",
    "#     pick = []\n",
    "\n",
    "#     x1 = boxes[:, 0]\n",
    "#     y1 = boxes[:, 1]\n",
    "#     x2 = boxes[:, 0] + boxes[:, 2]\n",
    "#     y2 = boxes[:, 1] + boxes[:, 3]\n",
    "\n",
    "#     area = (x2 - x1) * (y2 - y1)\n",
    "#     idxs = np.argsort(y2)\n",
    "\n",
    "#     while len(idxs) > 0:\n",
    "#         last = len(idxs) - 1\n",
    "#         i = idxs[last]\n",
    "#         pick.append(i)\n",
    "\n",
    "#         xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "#         yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "#         xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "#         yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "#         w = np.maximum(0, xx2 - xx1)\n",
    "#         h = np.maximum(0, yy2 - yy1)\n",
    "#         overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "#         idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "#     return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform multi-scale and multi-angle template matching\n",
    "# bounding_boxes = multi_scale_and_angle_template_matching(image, templates)\n",
    "\n",
    "# # Apply non-maxima suppression to reduce overlapping boxes\n",
    "# filtered_boxes = non_max_suppression(bounding_boxes)\n",
    "\n",
    "# # Draw bounding boxes on the original image for visualization\n",
    "# for (x, y, w, h) in filtered_boxes:\n",
    "#     cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "# # Create a filename based on scale and threshold\n",
    "# output_folder = 'output'  # Specify your output folder\n",
    "# os.makedirs(output_folder, exist_ok=True)  # Create output folder if it doesn't exist\n",
    "# filename = f\"detected_scale_1.jpg\"\n",
    "# filepath = os.path.join(output_folder, filename)\n",
    "\n",
    "# # Save the detected image\n",
    "# cv2.imwrite(filepath, image)\n",
    "\n",
    "# # Print the count of detected items\n",
    "# print(f'File Stored at: {filepath}\\nfile_name: {filename}')\n",
    "\n",
    "# # Show the result\n",
    "# cv2.imshow(\"Detected Icons\", image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageevn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
