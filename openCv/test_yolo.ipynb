{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_icons_yolo(image_path, yolo_net, yolo_layer_names, threshold=0.5):\n",
    "    img = cv2.imread(image_path)\n",
    "    height, width, channels = img.shape\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    # Pass the image blob through the network\n",
    "    yolo_net.setInput(blob)\n",
    "    outs = yolo_net.forward(yolo_layer_names)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # Process detections\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > threshold:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Define rectangle coordinates\n",
    "                x = center_x - w // 2\n",
    "                y = center_y - h // 2\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply non-maxima suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, threshold, 0.4)\n",
    "\n",
    "    # Draw results on image\n",
    "    for i in indices.flatten():\n",
    "        box = boxes[i]\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_folder: C:/Users/pis05408.PINNACLE/Desktop/Suraj/ObjectDetectionFlorPlan/Test\n"
     ]
    }
   ],
   "source": [
    "output_folder = 'C:/Users/pis05408.PINNACLE/Desktop/Suraj/ObjectDetectionFlorPlan/Test'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "print(f'output_folder: {output_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your target image and templates\n",
    "image_path = 'data/sample.jpg'\n",
    "# template_paths = ['data/test.jpg', 'data/test1.jpg', 'data/test1.jpg', 'data/test2.jpg', 'data/test3.jpg', 'data/test4.jpg', 'data/test5.jpg', 'data/test6.jpg']\n",
    "template_paths = ['data/test.jpg']\n",
    "\n",
    "# Read the images\n",
    "image = cv2.imread(image_path)\n",
    "templates = [cv2.imread(template_path) for template_path in template_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) C:\\b\\abs_daut97tdpo\\croot\\opencv-suite_1722029138522\\work\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov4.cfg in function 'cv::dnn::dnn4_v20240521::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load YOLO model (need pre-trained weights and config files)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov4.weights\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov4.cfg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mgetLayerNames()\n\u001b[0;32m      4\u001b[0m output_layers \u001b[38;5;241m=\u001b[39m [layer_names[i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m net\u001b[38;5;241m.\u001b[39mgetUnconnectedOutLayers()]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) C:\\b\\abs_daut97tdpo\\croot\\opencv-suite_1722029138522\\work\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov4.cfg in function 'cv::dnn::dnn4_v20240521::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "# Load YOLO model (need pre-trained weights and config files)\n",
    "net = cv2.dnn.readNet(\"yolov4.weights\", \"yolov4.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Use the YOLO model to detect icons\n",
    "detect_icons_yolo(\"floor_plan.png\", net, output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) C:\\b\\abs_daut97tdpo\\croot\\opencv-suite_1722029138522\\work\\modules\\core\\src\\batch_distance.cpp:275: error: (-215:Assertion failed) type == src2.type() && src1.cols == src2.cols && (type == CV_32F || type == CV_8U) in function 'cv::batchDistance'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m bf \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mBFMatcher(cv2\u001b[38;5;241m.\u001b[39mNORM_HAMMING, crossCheck\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Match descriptors\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescriptors1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptors2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Sort them in ascending order of distance\u001b[39;00m\n\u001b[0;32m     21\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(matches, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mdistance)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) C:\\b\\abs_daut97tdpo\\croot\\opencv-suite_1722029138522\\work\\modules\\core\\src\\batch_distance.cpp:275: error: (-215:Assertion failed) type == src2.type() && src1.cols == src2.cols && (type == CV_32F || type == CV_8U) in function 'cv::batchDistance'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load images\n",
    "floor_plan = cv2.imread('data/sample.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "icon = cv2.imread('data/test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initialize ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Find keypoints and descriptors\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(floor_plan, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(icon, None)\n",
    "\n",
    "# Create BFMatcher object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "# Sort them in ascending order of distance\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "# Draw matches\n",
    "img_matches = cv2.drawMatches(floor_plan, keypoints1, icon, keypoints2, matches[:10], None)\n",
    "# cv2.imshow('Matches', img_matches)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# Optionally, save the detected image\n",
    "cv2.imwrite('output/orb.jpg', img_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rotate_image(image, angle):\n",
    "#     (h, w) = image.shape[:2]\n",
    "#     center = (w / 2, h / 2)\n",
    "#     M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "#     cos = np.abs(M[0, 0])\n",
    "#     sin = np.abs(M[0, 1])\n",
    "#     new_w = int((h * sin) + (w * cos))\n",
    "#     new_h = int((h * cos) + (w * sin))\n",
    "#     M[0, 2] += (new_w / 2) - center[0]\n",
    "#     M[1, 2] += (new_h / 2) - center[1]\n",
    "#     rotated = cv2.warpAffine(image, M, (new_w, new_h))\n",
    "#     return rotated\n",
    "\n",
    "# def multi_scale_and_angle_template_matching(image, templates, threshold=0.7):\n",
    "#     bounding_boxes = []\n",
    "\n",
    "#     for template in templates:\n",
    "#         h, w = template.shape[:2]\n",
    "        \n",
    "#         # Loop over scales\n",
    "#         for scale in np.linspace(0.5, 1.5, num=10):  # Adjust scale range as needed\n",
    "#             resized_template = cv2.resize(template, (int(w * scale), int(h * scale)))\n",
    "#             res_h, res_w = resized_template.shape[:2]\n",
    "\n",
    "#             # Skip if resized template is larger than the image\n",
    "#             if res_h > image.shape[0] or res_w > image.shape[1]:\n",
    "#                 continue\n",
    "\n",
    "#             # Loop over angles\n",
    "#             for angle in [90, 180, 270]:  # Adjust angle step as needed\n",
    "#                 M = cv2.getRotationMatrix2D((res_w / 2, res_h / 2), angle, 1.0)\n",
    "#                 rotated_template = cv2.warpAffine(resized_template, M, (res_w, res_h))\n",
    "\n",
    "#                 # Template matching\n",
    "#                 result = cv2.matchTemplate(image, rotated_template, cv2.TM_CCOEFF_NORMED)\n",
    "#                 loc = np.where(result >= threshold)\n",
    "\n",
    "#                 # Record all locations where matches are found\n",
    "#                 for pt in zip(*loc[::-1]):  # Switch x and y coordinates\n",
    "#                     bounding_boxes.append((pt[0], pt[1], res_w, res_h))  # (x, y, width, height)\n",
    "\n",
    "#     return bounding_boxes\n",
    "\n",
    "# def non_max_suppression(boxes, overlapThresh=0.7):\n",
    "#     if len(boxes) == 0:\n",
    "#         return []\n",
    "\n",
    "#     boxes = np.array(boxes)\n",
    "#     pick = []\n",
    "\n",
    "#     x1 = boxes[:, 0]\n",
    "#     y1 = boxes[:, 1]\n",
    "#     x2 = boxes[:, 0] + boxes[:, 2]\n",
    "#     y2 = boxes[:, 1] + boxes[:, 3]\n",
    "\n",
    "#     area = (x2 - x1) * (y2 - y1)\n",
    "#     idxs = np.argsort(y2)\n",
    "\n",
    "#     while len(idxs) > 0:\n",
    "#         last = len(idxs) - 1\n",
    "#         i = idxs[last]\n",
    "#         pick.append(i)\n",
    "\n",
    "#         xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "#         yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "#         xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "#         yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "#         w = np.maximum(0, xx2 - xx1)\n",
    "#         h = np.maximum(0, yy2 - yy1)\n",
    "#         overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "#         idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "#     return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform multi-scale and multi-angle template matching\n",
    "# bounding_boxes = multi_scale_and_angle_template_matching(image, templates)\n",
    "\n",
    "# # Apply non-maxima suppression to reduce overlapping boxes\n",
    "# filtered_boxes = non_max_suppression(bounding_boxes)\n",
    "\n",
    "# # Draw bounding boxes on the original image for visualization\n",
    "# for (x, y, w, h) in filtered_boxes:\n",
    "#     cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "# # Create a filename based on scale and threshold\n",
    "# output_folder = 'output'  # Specify your output folder\n",
    "# os.makedirs(output_folder, exist_ok=True)  # Create output folder if it doesn't exist\n",
    "# filename = f\"detected_scale_1.jpg\"\n",
    "# filepath = os.path.join(output_folder, filename)\n",
    "\n",
    "# # Save the detected image\n",
    "# cv2.imwrite(filepath, image)\n",
    "\n",
    "# # Print the count of detected items\n",
    "# print(f'File Stored at: {filepath}\\nfile_name: {filename}')\n",
    "\n",
    "# # Show the result\n",
    "# cv2.imshow(\"Detected Icons\", image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageevn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
